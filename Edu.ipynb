{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN2sGCffnADMeRy3+viuW/t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamsalideepika/Edutuor-AI/blob/main/Edu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WH8JqoNSNhlB",
        "outputId": "52d98d91-393a-42b7-f6bc-085c613fc5cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"EduTutor AI: Personalized Learning Platform - Final Version\"\"\"\n",
        "\n",
        "# --- 1. Install Necessary Libraries ---\n",
        "# These commands are specific to Google Colab to install packages\n",
        "# not available by default or to upgrade them.\n",
        "!pip install PyPDF2\n",
        "!pip install -U bitsandbytes\n",
        "\n",
        "# --- 2. Import Libraries ---\n",
        "import gradio as gr\n",
        "import torch\n",
        "import PyPDF2\n",
        "import re\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# --- 3. Global Configurations and Initializations ---\n",
        "\n",
        "# Dummy user database for login authentication.\n",
        "# In a production environment, this would be a secure database\n",
        "# with hashed passwords (e.g., using bcrypt).\n",
        "if 'users_db' not in globals():\n",
        "    users_db = {\"student1\": \"pass123\", \"student2\": \"abc456\"}\n",
        "    print(\"Initialized dummy user database.\")\n",
        "\n",
        "# Store user session data (e.g., quiz attempts, progress).\n",
        "# Currently not fully utilized but serves as a placeholder.\n",
        "user_sessions = {}\n",
        "\n",
        "# Set device for model inference (GPU if available, else CPU).\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Device set to use: {device}\")\n",
        "\n",
        "# Initialize the text generation pipeline.\n",
        "# This will be loaded once when the script starts.\n",
        "generator = None\n",
        "try:\n",
        "    model_name = \"ibm-granite/granite-3.3-2b-instruct\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "    generator = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        max_new_tokens=700, # Increased max_new_tokens for potentially longer responses\n",
        "        # Add a common generation parameter to reduce repetition if the model supports it\n",
        "        # For 'granite' models, `do_sample=True` with `top_p` or `temperature` often works well.\n",
        "        do_sample=True,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9\n",
        "    )\n",
        "    print(\"‚úÖ Model and tokenizer loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading model/tokenizer: {e}\")\n",
        "    print(\"Please ensure you have sufficient RAM/GPU in your Colab session.\")\n",
        "    # Provide a placeholder generator if loading fails to prevent immediate crashes\n",
        "    def dummy_generator(prompt):\n",
        "        return [{\"generated_text\": \"Error: AI model not available. Please try again later or check server logs.\"}]\n",
        "    generator = dummy_generator\n",
        "\n",
        "\n",
        "# --- 4. Core AI Utility Functions ---\n",
        "\n",
        "def generate_response(prompt: str) -> str:\n",
        "    \"\"\"\n",
        "    Generates text using the loaded AI model.\n",
        "    Handles potential errors during text generation.\n",
        "    \"\"\"\n",
        "    if generator is None:\n",
        "        return \"‚ùå Error: AI model is not loaded. Cannot generate response.\"\n",
        "    try:\n",
        "        # The generator returns a list of dictionaries, extract the 'generated_text'.\n",
        "        response = generator(prompt)\n",
        "        if response and isinstance(response, list) and len(response) > 0 and \"generated_text\" in response[0]:\n",
        "            # The model might echo the prompt; we only want the new response.\n",
        "            # A simple way to do this is to remove the original prompt from the generated text.\n",
        "            full_text = response[0][\"generated_text\"]\n",
        "            if full_text.startswith(prompt):\n",
        "                return full_text[len(prompt):].strip()\n",
        "            return full_text.strip()\n",
        "        else:\n",
        "            print(f\"‚ùå Unexpected response format from generator: {response}\")\n",
        "            return \"‚ùå Error: Unexpected response format from AI model. Please try again.\"\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error during text generation for prompt '{prompt[:50]}...': {e}\")\n",
        "        return f\"‚ùå Error during text generation: {e}. Please simplify your request or try again.\"\n",
        "\n",
        "# --- 5. Specific Learning Functionalities ---\n",
        "\n",
        "def get_concept_explanation(concept: str) -> str:\n",
        "    \"\"\"Provides a simple explanation of a given concept.\"\"\"\n",
        "    if not concept.strip():\n",
        "        return \"Please enter a concept to get an explanation.\"\n",
        "    prompt = f\"\"\"\n",
        "Explain the concept of '{concept}' in a simple and clear way that a 15-year-old student can easily understand. Include examples and real-world applications if possible.\n",
        "\"\"\"\n",
        "    return generate_response(prompt)\n",
        "\n",
        "def get_language_basics(language: str) -> str:\n",
        "    \"\"\"Teaches basic grammar and vocabulary for a specified language.\"\"\"\n",
        "    if not language:\n",
        "        return \"Please select a language to learn.\"\n",
        "    prompt = f\"\"\"\n",
        "Teach me the basics of {language} language. Include grammar rules, common vocabulary, and parts of speech. Provide at least 5-7 key phrases or words.\n",
        "\"\"\"\n",
        "    return generate_response(prompt)\n",
        "\n",
        "def extract_text_from_pdf(pdf_file) -> tuple[str, str | None]:\n",
        "    \"\"\"\n",
        "    Extracts text from a PDF file.\n",
        "    Returns extracted text and an error message (if any).\n",
        "    \"\"\"\n",
        "    if not pdf_file:\n",
        "        return None, \"‚ùå Please upload a PDF file.\"\n",
        "    try:\n",
        "        reader = PyPDF2.PdfReader(pdf_file)\n",
        "        # Join text from all pages, ensuring only pages with text are included\n",
        "        text = \" \".join([page.extract_text() for page in reader.pages if page.extract_text()])\n",
        "        if not text.strip(): # Check if extracted text is empty or just whitespace\n",
        "            return None, \"‚ùå Could not extract readable text from PDF. It might be an image-based PDF or empty.\"\n",
        "        return text, None\n",
        "    except PyPDF2.errors.PdfReadError:\n",
        "        return None, \"‚ùå Invalid PDF file. Please upload a valid PDF.\"\n",
        "    except Exception as e:\n",
        "        return None, f\"‚ùå Failed to process PDF: {e}. Please ensure it's a valid PDF.\"\n",
        "\n",
        "def generate_test_from_content(text_content: str) -> str:\n",
        "    \"\"\"Generates multiple-choice questions from provided text content.\"\"\"\n",
        "    if not text_content.strip():\n",
        "        return \"‚ùå No content provided for test generation.\"\n",
        "\n",
        "    # Limit content length for prompt to avoid exceeding model's context window\n",
        "    # Approximately 1000 tokens for context, leaving room for instructions and output\n",
        "    max_content_length = 3000 # Characters, not tokens, but a rough limit\n",
        "    if len(text_content) > max_content_length:\n",
        "        text_content = text_content[:max_content_length] + \"...\"\n",
        "        print(f\"Truncated PDF content to {max_content_length} characters for test generation.\")\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "Generate 3-5 multiple-choice questions from the following content. Focus on key information.\n",
        "\n",
        "Content:\n",
        "{text_content}\n",
        "\n",
        "Format each question strictly like this:\n",
        "Qn: <question text>\n",
        "A. <option A text>\n",
        "B. <option B text>\n",
        "C. <option C text>\n",
        "D. <option D text>\n",
        "Correct Answer: <correct letter A, B, C, or D>\n",
        "\n",
        "Example:\n",
        "Q1: What is the capital of France?\n",
        "A. Berlin\n",
        "B. Paris\n",
        "C. Rome\n",
        "D. Madrid\n",
        "Correct Answer: B\n",
        "\"\"\"\n",
        "    return generate_response(prompt)\n",
        "\n",
        "def generate_quiz_content(topic: str) -> list[dict]:\n",
        "    \"\"\"\n",
        "    Generates a 5-question multiple-choice quiz on a given topic.\n",
        "    Returns a list of dictionaries with parsed questions, options, and correct answers.\n",
        "    \"\"\"\n",
        "    if not topic.strip():\n",
        "        return [] # Return empty list if no topic\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "Generate a 5-question multiple choice quiz on the topic: {topic}.\n",
        "Each question should have options A, B, C, D.\n",
        "Indicate the Correct Answer for each question.\n",
        "\n",
        "Format each question strictly like this:\n",
        "Qn: <question text>\n",
        "A. <option A text>\n",
        "B. <option B text>\n",
        "C. <option C text>\n",
        "D. <option D text>\n",
        "Correct Answer: <correct letter A, B, C, or D>\n",
        "\n",
        "Example:\n",
        "Q1: What is the largest planet in our solar system?\n",
        "A. Mars\n",
        "B. Jupiter\n",
        "C. Earth\n",
        "D. Venus\n",
        "Correct Answer: B\n",
        "\"\"\"\n",
        "    quiz_text = generate_response(prompt)\n",
        "    print(f\"Raw Quiz Generator Output: {quiz_text}\")\n",
        "\n",
        "    questions = []\n",
        "    # Regex to robustly parse the questions, options, and correct answers\n",
        "    # This pattern is quite flexible to handle slight variations in spacing\n",
        "    question_pattern = re.compile(\n",
        "        r'Q(\\d+):\\s*(.*?)\\n' # Qn: <question>\n",
        "        r'\\s*A\\.\\s*(.*?)\\n' # A. <option A>\n",
        "        r'\\s*B\\.\\s*(.*?)\\n' # B. <option B>\n",
        "        r'\\s*C\\.\\s*(.*?)\\n' # C. <option C>\n",
        "        r'\\s*D\\.\\s*(.*?)\\n' # D. <option D>\n",
        "        r'\\s*Correct Answer:\\s*([A-D])\\.', # Correct Answer: <letter>.\n",
        "        re.DOTALL # Allows . to match newlines\n",
        "    )\n",
        "    matches = question_pattern.findall(quiz_text)\n",
        "\n",
        "    print(f\"Matches found by regex: {matches}\")\n",
        "\n",
        "    for match in matches:\n",
        "        try:\n",
        "            # Extracting groups from the regex match\n",
        "            # match[0] is question number (e.g., '1')\n",
        "            # match[1] is question text\n",
        "            # match[2] to match[5] are options A-D\n",
        "            # match[6] is correct answer letter\n",
        "            question_text = match[1].strip()\n",
        "            options_dict = {\n",
        "                'A': match[2].strip(),\n",
        "                'B': match[3].strip(),\n",
        "                'C': match[4].strip(),\n",
        "                'D': match[5].strip()\n",
        "            }\n",
        "            correct_answer = match[6].strip().upper() # Ensure consistent casing\n",
        "\n",
        "            questions.append({\n",
        "                \"question\": question_text,\n",
        "                \"options\": options_dict,\n",
        "                \"correct_answer\": correct_answer\n",
        "            })\n",
        "        except IndexError as ie:\n",
        "            print(f\"Warning: Could not parse a quiz question due to unexpected format in match: {match}. Error: {ie}\")\n",
        "            continue # Skip this malformed question\n",
        "    print(f\"Final Parsed Questions list: {questions}\")\n",
        "    return questions\n",
        "\n",
        "# --- 6. Authentication Logic ---\n",
        "\n",
        "def authenticate_user(username: str, password: str) -> bool:\n",
        "    \"\"\"Authenticates a user against the dummy database.\"\"\"\n",
        "    return users_db.get(username) == password\n",
        "\n",
        "def register_new_user(new_username: str, new_password: str) -> str:\n",
        "    \"\"\"Registers a new user in the dummy database.\"\"\"\n",
        "    if not new_username.strip() or not new_password.strip():\n",
        "        return \"‚ùå Username and password cannot be empty!\"\n",
        "    if new_username in users_db:\n",
        "        return \"‚ùå Username already exists! Please choose another.\"\n",
        "    else:\n",
        "        users_db[new_username] = new_password\n",
        "        return \"‚úÖ User registered successfully. You can now login.\"\n",
        "\n",
        "# --- 7. Gradio Interface Logic Functions ---\n",
        "\n",
        "def login_handler(user: str, pwd: str):\n",
        "    \"\"\"\n",
        "    Handles user login, updates UI visibility and status.\n",
        "    Returns: (gr.update for app_ui, login_status text, username_state value)\n",
        "    \"\"\"\n",
        "    if authenticate_user(user, pwd):\n",
        "        # Update app_ui to be visible, login status, and set username state\n",
        "        return gr.update(visible=True), \"‚úÖ Login successful. Welcome!\", user\n",
        "    else:\n",
        "        # Keep app_ui hidden, update login status, and clear username state\n",
        "        return gr.update(visible=False), \"‚ùå Invalid credentials! Please try again.\", \"\"\n",
        "\n",
        "def process_learning_requests(username: str, concept: str, language: str, pdf_file):\n",
        "    \"\"\"\n",
        "    Main function to process concept explanation, language learning, and PDF test generation.\n",
        "    Returns: (concept_output, language_output, test_pdf_output, status_message)\n",
        "    \"\"\"\n",
        "    # Initialize outputs with default messages\n",
        "    concept_output = \"No concept explanation requested or provided yet.\"\n",
        "    language_output = \"No language basics requested or provided yet.\"\n",
        "    test_pdf_output = \"Upload a PDF to generate a test from its content.\"\n",
        "    status_message = \"Processing your requests...\"\n",
        "\n",
        "    # Concept Understanding\n",
        "    if concept.strip():\n",
        "        concept_output = get_concept_explanation(concept)\n",
        "    else:\n",
        "        concept_output = \"Enter a concept above to get an explanation.\"\n",
        "\n",
        "    # Language Learning\n",
        "    if language: # Radio button ensures a selection if user interacts\n",
        "        language_output = get_language_basics(language)\n",
        "    else:\n",
        "        language_output = \"Select a language above to learn its basics.\"\n",
        "\n",
        "    # PDF Test Generation\n",
        "    if pdf_file:\n",
        "        status_message = \"Extracting text from PDF and generating test...\"\n",
        "        pdf_text, pdf_error = extract_text_from_pdf(pdf_file)\n",
        "        if pdf_error:\n",
        "            test_pdf_output = pdf_error\n",
        "        elif pdf_text:\n",
        "            test_pdf_output = generate_test_from_content(pdf_text)\n",
        "        else:\n",
        "            test_pdf_output = \"Failed to extract text or generate test from PDF. Check file format.\"\n",
        "    else:\n",
        "        test_pdf_output = \"Upload a PDF file to generate a test from its content.\"\n",
        "\n",
        "    # Final status message\n",
        "    status_message = \"All learning requests processed.\"\n",
        "    return concept_output, language_output, test_pdf_output\n",
        "\n",
        "def process_quiz_request(quiz_topic: str) -> str:\n",
        "    \"\"\"\n",
        "    Generates a quiz for the given topic and formats it for display.\n",
        "    Returns: Formatted quiz string.\n",
        "    \"\"\"\n",
        "    if not quiz_topic.strip():\n",
        "        return \"Please enter a topic to generate a quiz.\"\n",
        "\n",
        "    quiz_data = generate_quiz_content(quiz_topic)\n",
        "\n",
        "    formatted_quiz_output = \"\"\n",
        "    if quiz_data:\n",
        "        formatted_quiz_output += f\"### Quiz on: {quiz_topic}\\n\\n\"\n",
        "        for i, q in enumerate(quiz_data):\n",
        "            formatted_quiz_output += f\"**Q{i+1}:** {q['question']}\\n\"\n",
        "            for option_key, option_value in q['options'].items():\n",
        "                formatted_quiz_output += f\"  **{option_key}.** {option_value}\\n\"\n",
        "            formatted_quiz_output += f\"  **Correct Answer:** {q['correct_answer']}\\n\\n\"\n",
        "    else:\n",
        "        formatted_quiz_output = \"Could not generate quiz for the given topic. The AI might not have sufficient knowledge or the request was too vague.\"\n",
        "\n",
        "    print(f\"Formatted Quiz Output for Gradio: {formatted_quiz_output}\")\n",
        "    return formatted_quiz_output\n",
        "\n",
        "# --- 8. Gradio User Interface Definition ---\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Soft(), title=\"EduTutor AI\") as interface:\n",
        "    gr.Markdown(\"# üë©‚Äçüè´ EduTutor AI: Personalized Learning Platform\")\n",
        "    gr.Markdown(\"Welcome to EduTutor AI! Your personalized learning assistant. Login or Register to get started.\")\n",
        "\n",
        "    # State variable to hold the logged-in username\n",
        "    username_state = gr.State(\"\")\n",
        "\n",
        "    # Top-level Tabs for Login/Register\n",
        "    with gr.Tabs():\n",
        "        with gr.TabItem(\"Login\"):\n",
        "            with gr.Row():\n",
        "                login_user = gr.Textbox(label=\"Username\", placeholder=\"student1\", scale=1)\n",
        "                login_pwd = gr.Textbox(label=\"Password\", type=\"password\", placeholder=\"pass123\", scale=1)\n",
        "            login_button = gr.Button(\"Login\", variant=\"primary\", scale=0) # Scale=0 for auto-sizing\n",
        "            login_status = gr.Textbox(label=\"Login Status\", interactive=False, placeholder=\"Enter credentials and click Login.\")\n",
        "\n",
        "        with gr.TabItem(\"Register\"):\n",
        "            with gr.Row():\n",
        "                new_user = gr.Textbox(label=\"New Username\", placeholder=\"Enter desired username\", scale=1)\n",
        "                new_pwd = gr.Textbox(label=\"New Password\", type=\"password\", placeholder=\"Create a password\", scale=1)\n",
        "            register_button = gr.Button(\"Register\", variant=\"secondary\", scale=0)\n",
        "            registration_status = gr.Textbox(label=\"Registration Status\", interactive=False, placeholder=\"Click Register to create account.\")\n",
        "            register_button.click(fn=register_new_user, inputs=[new_user, new_pwd], outputs=registration_status)\n",
        "\n",
        "    # Main Application UI - Hidden until login\n",
        "    with gr.Column(visible=False, elem_id=\"app_ui_column\") as app_ui:\n",
        "        gr.Markdown(\"---\")\n",
        "        gr.Markdown(\"## Your Learning Hub\")\n",
        "        gr.Markdown(\"Use the tabs below to explore concepts, learn languages, generate tests from PDFs, or create quizzes.\")\n",
        "\n",
        "        # Tabs for different functionalities within the main app\n",
        "        with gr.Tabs():\n",
        "            with gr.TabItem(\"Concepts & Language\"):\n",
        "                gr.Markdown(\"### Explore Concepts and Learn Languages\")\n",
        "                with gr.Row():\n",
        "                    concept_input = gr.Textbox(\n",
        "                        label=\"Enter Concept to Explain (e.g., Photosynthesis, Machine Learning)\",\n",
        "                        placeholder=\"Generative AI\",\n",
        "                        lines=2, # More lines for concept input\n",
        "                        scale=2\n",
        "                    )\n",
        "                    language_radio = gr.Radio(\n",
        "                        choices=[\"English\", \"Hindi\", \"French\", \"Spanish\"], # Added more language options\n",
        "                        label=\"Choose Language for Basics\",\n",
        "                        value=\"English\", # Default selection\n",
        "                        scale=1\n",
        "                    )\n",
        "                pdf_upload = gr.File(\n",
        "                    label=\"Upload PDF for Test Generation (Optional)\",\n",
        "                    file_types=[\".pdf\"],\n",
        "                    file_count=\"single\" # Allow only one file\n",
        "                )\n",
        "\n",
        "                run_learning_btn = gr.Button(\"Get Explanations & Generate PDF Test\", variant=\"primary\")\n",
        "\n",
        "                gr.Markdown(\"---\")\n",
        "                gr.Markdown(\"### Outputs:\")\n",
        "                # Using Markdown components for outputs for better text rendering and copy button\n",
        "                concept_output_box = gr.Markdown(label=\"Concept Explanation\", show_copy_button=True)\n",
        "                language_output_box = gr.Markdown(label=\"Language Learning Basics\", show_copy_button=True)\n",
        "                pdf_test_output_box = gr.Markdown(label=\"Generated Test from PDF Content\", show_copy_button=True)\n",
        "\n",
        "                # Link the button click to the processing function\n",
        "                run_learning_btn.click(\n",
        "                    fn=process_learning_requests,\n",
        "                    inputs=[username_state, concept_input, language_radio, pdf_upload],\n",
        "                    outputs=[concept_output_box, language_output_box, pdf_test_output_box]\n",
        "                )\n",
        "\n",
        "            with gr.TabItem(\"Quiz Generator\"):\n",
        "                gr.Markdown(\"### Create a Quick Quiz on Any Topic\")\n",
        "                quiz_topic_input = gr.Textbox(\n",
        "                    label=\"Enter Topic for Quiz (e.g., World War II, Python Programming)\",\n",
        "                    placeholder=\"Artificial Intelligence\",\n",
        "                    lines=2\n",
        "                )\n",
        "                generate_quiz_btn = gr.Button(\"Generate Quiz\", variant=\"primary\")\n",
        "\n",
        "                gr.Markdown(\"---\")\n",
        "                gr.Markdown(\"### Generated Quiz:\")\n",
        "                # Changed to gr.Markdown for better formatting of the quiz content\n",
        "                # Added an initial placeholder text and set lines for visual space.\n",
        "                quiz_output_box = gr.Markdown(\n",
        "                    value=\"Your generated quiz will appear here. It may take a moment...\",\n",
        "                    label=\"Generated Quiz\",\n",
        "                    show_copy_button=True,\n",
        "                    # We don't use 'lines' with gr.Markdown directly, but the content will expand.\n",
        "                    # For a fixed box, you'd use gr.Textbox. If the content is long, Markdown works well.\n",
        "                )\n",
        "\n",
        "                # Link the quiz generation button\n",
        "                generate_quiz_btn.click(\n",
        "                    fn=process_quiz_request,\n",
        "                    inputs=[quiz_topic_input],\n",
        "                    outputs=[quiz_output_box]\n",
        "                )\n",
        "\n",
        "    # Link the login button to its handler\n",
        "    login_button.click(\n",
        "        fn=login_handler,\n",
        "        inputs=[login_user, login_pwd],\n",
        "        outputs=[app_ui, login_status, username_state]\n",
        "    )\n",
        "\n",
        "# --- 9. Launch the Gradio Interface ---\n",
        "# debug=True provides more console output for debugging.\n",
        "# share=True generates a public URL, useful for Colab.\n",
        "interface.launch(debug=True, share=True)"
      ]
    }
  ]
}