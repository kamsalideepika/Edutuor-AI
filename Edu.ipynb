{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN2sGCffnADMeRy3+viuW/t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b4adaae96a124151af75c996cb8b012d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_650f9afb02944b8d821e336bbf762d5b",
              "IPY_MODEL_9a6b390d1fc44feabf52b16d8b531d07",
              "IPY_MODEL_6d51217f3a384364b021cb7e044b2058"
            ],
            "layout": "IPY_MODEL_29321c152e844a60912072230eedf89c"
          }
        },
        "650f9afb02944b8d821e336bbf762d5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c74bdfd42be04604a9e6f57717da7e86",
            "placeholder": "​",
            "style": "IPY_MODEL_c07f7813105e4e5b81825ee756bb932b",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "9a6b390d1fc44feabf52b16d8b531d07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06433d333307460c8cf0dc1ce6536866",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e8794e72a024aaa857bbfdcd9db095b",
            "value": 2
          }
        },
        "6d51217f3a384364b021cb7e044b2058": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e5d204a9a9e4523852c3507da704411",
            "placeholder": "​",
            "style": "IPY_MODEL_977f5a20a7484d2789dfa161ab926b2d",
            "value": " 2/2 [00:39&lt;00:00, 16.42s/it]"
          }
        },
        "29321c152e844a60912072230eedf89c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c74bdfd42be04604a9e6f57717da7e86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c07f7813105e4e5b81825ee756bb932b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06433d333307460c8cf0dc1ce6536866": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e8794e72a024aaa857bbfdcd9db095b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e5d204a9a9e4523852c3507da704411": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "977f5a20a7484d2789dfa161ab926b2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b49b6fd29b04d9b810d1f4d8d2b3a6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_051882c7c7f74b0390598a105872a88b",
              "IPY_MODEL_aef0ae2f14dc4aaaa7a067f341151ab7",
              "IPY_MODEL_ac985274c59b4f5b917612a046413443"
            ],
            "layout": "IPY_MODEL_909753050e10483b96cf9e7304085a0d"
          }
        },
        "051882c7c7f74b0390598a105872a88b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d4add14901848ca964b54055074c012",
            "placeholder": "​",
            "style": "IPY_MODEL_893422abbd1943beb073721f3b2a6bec",
            "value": "generation_config.json: 100%"
          }
        },
        "aef0ae2f14dc4aaaa7a067f341151ab7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81c83312b32544da82be218b7d54733d",
            "max": 132,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_53ae755d2f874aa9b58dd5e695b837f8",
            "value": 132
          }
        },
        "ac985274c59b4f5b917612a046413443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67c6b5a62cc6463b96a7f7a1045dbfa5",
            "placeholder": "​",
            "style": "IPY_MODEL_56c80915c78b42409b8c9a9b088406e5",
            "value": " 132/132 [00:00&lt;00:00, 14.8kB/s]"
          }
        },
        "909753050e10483b96cf9e7304085a0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d4add14901848ca964b54055074c012": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "893422abbd1943beb073721f3b2a6bec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81c83312b32544da82be218b7d54733d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53ae755d2f874aa9b58dd5e695b837f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67c6b5a62cc6463b96a7f7a1045dbfa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56c80915c78b42409b8c9a9b088406e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamsalideepika/Edutuor-AI/blob/main/Edu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b4adaae96a124151af75c996cb8b012d",
            "650f9afb02944b8d821e336bbf762d5b",
            "9a6b390d1fc44feabf52b16d8b531d07",
            "6d51217f3a384364b021cb7e044b2058",
            "29321c152e844a60912072230eedf89c",
            "c74bdfd42be04604a9e6f57717da7e86",
            "c07f7813105e4e5b81825ee756bb932b",
            "06433d333307460c8cf0dc1ce6536866",
            "0e8794e72a024aaa857bbfdcd9db095b",
            "6e5d204a9a9e4523852c3507da704411",
            "977f5a20a7484d2789dfa161ab926b2d",
            "6b49b6fd29b04d9b810d1f4d8d2b3a6f",
            "051882c7c7f74b0390598a105872a88b",
            "aef0ae2f14dc4aaaa7a067f341151ab7",
            "ac985274c59b4f5b917612a046413443",
            "909753050e10483b96cf9e7304085a0d",
            "7d4add14901848ca964b54055074c012",
            "893422abbd1943beb073721f3b2a6bec",
            "81c83312b32544da82be218b7d54733d",
            "53ae755d2f874aa9b58dd5e695b837f8",
            "67c6b5a62cc6463b96a7f7a1045dbfa5",
            "56c80915c78b42409b8c9a9b088406e5"
          ]
        },
        "id": "WH8JqoNSNhlB",
        "outputId": "897e5aee-ff71-4f8c-a003-53f591100898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.46.0)\n",
            "Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n",
            "Initialized dummy user database.\n",
            "Device set to use: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4adaae96a124151af75c996cb8b012d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b49b6fd29b04d9b810d1f4d8d2b3a6f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model and tokenizer loaded successfully.\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://ad6904477c5730b5b4.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ad6904477c5730b5b4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"EduTutor AI: Personalized Learning Platform - Final Version\"\"\"\n",
        "\n",
        "# --- 1. Install Necessary Libraries ---\n",
        "# These commands are specific to Google Colab to install packages\n",
        "# not available by default or to upgrade them.\n",
        "!pip install PyPDF2\n",
        "!pip install -U bitsandbytes\n",
        "\n",
        "# --- 2. Import Libraries ---\n",
        "import gradio as gr\n",
        "import torch\n",
        "import PyPDF2\n",
        "import re\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# --- 3. Global Configurations and Initializations ---\n",
        "\n",
        "# Dummy user database for login authentication.\n",
        "# In a production environment, this would be a secure database\n",
        "# with hashed passwords (e.g., using bcrypt).\n",
        "if 'users_db' not in globals():\n",
        "    users_db = {\"student1\": \"pass123\", \"student2\": \"abc456\"}\n",
        "    print(\"Initialized dummy user database.\")\n",
        "\n",
        "# Store user session data (e.g., quiz attempts, progress).\n",
        "# Currently not fully utilized but serves as a placeholder.\n",
        "user_sessions = {}\n",
        "\n",
        "# Set device for model inference (GPU if available, else CPU).\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Device set to use: {device}\")\n",
        "\n",
        "# Initialize the text generation pipeline.\n",
        "# This will be loaded once when the script starts.\n",
        "generator = None\n",
        "try:\n",
        "    model_name = \"ibm-granite/granite-3.3-2b-instruct\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "    generator = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        max_new_tokens=700, # Increased max_new_tokens for potentially longer responses\n",
        "        # Add a common generation parameter to reduce repetition if the model supports it\n",
        "        # For 'granite' models, `do_sample=True` with `top_p` or `temperature` often works well.\n",
        "        do_sample=True,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9\n",
        "    )\n",
        "    print(\"✅ Model and tokenizer loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error loading model/tokenizer: {e}\")\n",
        "    print(\"Please ensure you have sufficient RAM/GPU in your Colab session.\")\n",
        "    # Provide a placeholder generator if loading fails to prevent immediate crashes\n",
        "    def dummy_generator(prompt):\n",
        "        return [{\"generated_text\": \"Error: AI model not available. Please try again later or check server logs.\"}]\n",
        "    generator = dummy_generator\n",
        "\n",
        "\n",
        "# --- 4. Core AI Utility Functions ---\n",
        "\n",
        "def generate_response(prompt: str) -> str:\n",
        "    \"\"\"\n",
        "    Generates text using the loaded AI model.\n",
        "    Handles potential errors during text generation.\n",
        "    \"\"\"\n",
        "    if generator is None:\n",
        "        return \"❌ Error: AI model is not loaded. Cannot generate response.\"\n",
        "    try:\n",
        "        # The generator returns a list of dictionaries, extract the 'generated_text'.\n",
        "        response = generator(prompt)\n",
        "        if response and isinstance(response, list) and len(response) > 0 and \"generated_text\" in response[0]:\n",
        "            # The model might echo the prompt; we only want the new response.\n",
        "            # A simple way to do this is to remove the original prompt from the generated text.\n",
        "            full_text = response[0][\"generated_text\"]\n",
        "            if full_text.startswith(prompt):\n",
        "                return full_text[len(prompt):].strip()\n",
        "            return full_text.strip()\n",
        "        else:\n",
        "            print(f\"❌ Unexpected response format from generator: {response}\")\n",
        "            return \"❌ Error: Unexpected response format from AI model. Please try again.\"\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error during text generation for prompt '{prompt[:50]}...': {e}\")\n",
        "        return f\"❌ Error during text generation: {e}. Please simplify your request or try again.\"\n",
        "\n",
        "# --- 5. Specific Learning Functionalities ---\n",
        "\n",
        "def get_concept_explanation(concept: str) -> str:\n",
        "    \"\"\"Provides a simple explanation of a given concept.\"\"\"\n",
        "    if not concept.strip():\n",
        "        return \"Please enter a concept to get an explanation.\"\n",
        "    prompt = f\"\"\"\n",
        "Explain the concept of '{concept}' in a simple and clear way that a 15-year-old student can easily understand. Include examples and real-world applications if possible.\n",
        "\"\"\"\n",
        "    return generate_response(prompt)\n",
        "\n",
        "def get_language_basics(language: str) -> str:\n",
        "    \"\"\"Teaches basic grammar and vocabulary for a specified language.\"\"\"\n",
        "    if not language:\n",
        "        return \"Please select a language to learn.\"\n",
        "    prompt = f\"\"\"\n",
        "Teach me the basics of {language} language. Include grammar rules, common vocabulary, and parts of speech. Provide at least 5-7 key phrases or words.\n",
        "\"\"\"\n",
        "    return generate_response(prompt)\n",
        "\n",
        "def extract_text_from_pdf(pdf_file) -> tuple[str, str | None]:\n",
        "    \"\"\"\n",
        "    Extracts text from a PDF file.\n",
        "    Returns extracted text and an error message (if any).\n",
        "    \"\"\"\n",
        "    if not pdf_file:\n",
        "        return None, \"❌ Please upload a PDF file.\"\n",
        "    try:\n",
        "        reader = PyPDF2.PdfReader(pdf_file)\n",
        "        # Join text from all pages, ensuring only pages with text are included\n",
        "        text = \" \".join([page.extract_text() for page in reader.pages if page.extract_text()])\n",
        "        if not text.strip(): # Check if extracted text is empty or just whitespace\n",
        "            return None, \"❌ Could not extract readable text from PDF. It might be an image-based PDF or empty.\"\n",
        "        return text, None\n",
        "    except PyPDF2.errors.PdfReadError:\n",
        "        return None, \"❌ Invalid PDF file. Please upload a valid PDF.\"\n",
        "    except Exception as e:\n",
        "        return None, f\"❌ Failed to process PDF: {e}. Please ensure it's a valid PDF.\"\n",
        "\n",
        "def generate_test_from_content(text_content: str) -> str:\n",
        "    \"\"\"Generates multiple-choice questions from provided text content.\"\"\"\n",
        "    if not text_content.strip():\n",
        "        return \"❌ No content provided for test generation.\"\n",
        "\n",
        "    # Limit content length for prompt to avoid exceeding model's context window\n",
        "    # Approximately 1000 tokens for context, leaving room for instructions and output\n",
        "    max_content_length = 3000 # Characters, not tokens, but a rough limit\n",
        "    if len(text_content) > max_content_length:\n",
        "        text_content = text_content[:max_content_length] + \"...\"\n",
        "        print(f\"Truncated PDF content to {max_content_length} characters for test generation.\")\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "Generate 3-5 multiple-choice questions from the following content. Focus on key information.\n",
        "\n",
        "Content:\n",
        "{text_content}\n",
        "\n",
        "Format each question strictly like this:\n",
        "Qn: <question text>\n",
        "A. <option A text>\n",
        "B. <option B text>\n",
        "C. <option C text>\n",
        "D. <option D text>\n",
        "Correct Answer: <correct letter A, B, C, or D>\n",
        "\n",
        "Example:\n",
        "Q1: What is the capital of France?\n",
        "A. Berlin\n",
        "B. Paris\n",
        "C. Rome\n",
        "D. Madrid\n",
        "Correct Answer: B\n",
        "\"\"\"\n",
        "    return generate_response(prompt)\n",
        "\n",
        "def generate_quiz_content(topic: str) -> list[dict]:\n",
        "    \"\"\"\n",
        "    Generates a 5-question multiple-choice quiz on a given topic.\n",
        "    Returns a list of dictionaries with parsed questions, options, and correct answers.\n",
        "    \"\"\"\n",
        "    if not topic.strip():\n",
        "        return [] # Return empty list if no topic\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "Generate a 5-question multiple choice quiz on the topic: {topic}.\n",
        "Each question should have options A, B, C, D.\n",
        "Indicate the Correct Answer for each question.\n",
        "\n",
        "Format each question strictly like this:\n",
        "Qn: <question text>\n",
        "A. <option A text>\n",
        "B. <option B text>\n",
        "C. <option C text>\n",
        "D. <option D text>\n",
        "Correct Answer: <correct letter A, B, C, or D>\n",
        "\n",
        "Example:\n",
        "Q1: What is the largest planet in our solar system?\n",
        "A. Mars\n",
        "B. Jupiter\n",
        "C. Earth\n",
        "D. Venus\n",
        "Correct Answer: B\n",
        "\"\"\"\n",
        "    quiz_text = generate_response(prompt)\n",
        "    print(f\"Raw Quiz Generator Output: {quiz_text}\")\n",
        "\n",
        "    questions = []\n",
        "    # Regex to robustly parse the questions, options, and correct answers\n",
        "    # This pattern is quite flexible to handle slight variations in spacing\n",
        "    question_pattern = re.compile(\n",
        "        r'Q(\\d+):\\s*(.*?)\\n' # Qn: <question>\n",
        "        r'\\s*A\\.\\s*(.*?)\\n' # A. <option A>\n",
        "        r'\\s*B\\.\\s*(.*?)\\n' # B. <option B>\n",
        "        r'\\s*C\\.\\s*(.*?)\\n' # C. <option C>\n",
        "        r'\\s*D\\.\\s*(.*?)\\n' # D. <option D>\n",
        "        r'\\s*Correct Answer:\\s*([A-D])\\.', # Correct Answer: <letter>.\n",
        "        re.DOTALL # Allows . to match newlines\n",
        "    )\n",
        "    matches = question_pattern.findall(quiz_text)\n",
        "\n",
        "    print(f\"Matches found by regex: {matches}\")\n",
        "\n",
        "    for match in matches:\n",
        "        try:\n",
        "            # Extracting groups from the regex match\n",
        "            # match[0] is question number (e.g., '1')\n",
        "            # match[1] is question text\n",
        "            # match[2] to match[5] are options A-D\n",
        "            # match[6] is correct answer letter\n",
        "            question_text = match[1].strip()\n",
        "            options_dict = {\n",
        "                'A': match[2].strip(),\n",
        "                'B': match[3].strip(),\n",
        "                'C': match[4].strip(),\n",
        "                'D': match[5].strip()\n",
        "            }\n",
        "            correct_answer = match[6].strip().upper() # Ensure consistent casing\n",
        "\n",
        "            questions.append({\n",
        "                \"question\": question_text,\n",
        "                \"options\": options_dict,\n",
        "                \"correct_answer\": correct_answer\n",
        "            })\n",
        "        except IndexError as ie:\n",
        "            print(f\"Warning: Could not parse a quiz question due to unexpected format in match: {match}. Error: {ie}\")\n",
        "            continue # Skip this malformed question\n",
        "    print(f\"Final Parsed Questions list: {questions}\")\n",
        "    return questions\n",
        "\n",
        "# --- 6. Authentication Logic ---\n",
        "\n",
        "def authenticate_user(username: str, password: str) -> bool:\n",
        "    \"\"\"Authenticates a user against the dummy database.\"\"\"\n",
        "    return users_db.get(username) == password\n",
        "\n",
        "def register_new_user(new_username: str, new_password: str) -> str:\n",
        "    \"\"\"Registers a new user in the dummy database.\"\"\"\n",
        "    if not new_username.strip() or not new_password.strip():\n",
        "        return \"❌ Username and password cannot be empty!\"\n",
        "    if new_username in users_db:\n",
        "        return \"❌ Username already exists! Please choose another.\"\n",
        "    else:\n",
        "        users_db[new_username] = new_password\n",
        "        return \"✅ User registered successfully. You can now login.\"\n",
        "\n",
        "# --- 7. Gradio Interface Logic Functions ---\n",
        "\n",
        "def login_handler(user: str, pwd: str):\n",
        "    \"\"\"\n",
        "    Handles user login, updates UI visibility and status.\n",
        "    Returns: (gr.update for app_ui, login_status text, username_state value)\n",
        "    \"\"\"\n",
        "    if authenticate_user(user, pwd):\n",
        "        # Update app_ui to be visible, login status, and set username state\n",
        "        return gr.update(visible=True), \"✅ Login successful. Welcome!\", user\n",
        "    else:\n",
        "        # Keep app_ui hidden, update login status, and clear username state\n",
        "        return gr.update(visible=False), \"❌ Invalid credentials! Please try again.\", \"\"\n",
        "\n",
        "def process_learning_requests(username: str, concept: str, language: str, pdf_file):\n",
        "    \"\"\"\n",
        "    Main function to process concept explanation, language learning, and PDF test generation.\n",
        "    Returns: (concept_output, language_output, test_pdf_output, status_message)\n",
        "    \"\"\"\n",
        "    # Initialize outputs with default messages\n",
        "    concept_output = \"No concept explanation requested or provided yet.\"\n",
        "    language_output = \"No language basics requested or provided yet.\"\n",
        "    test_pdf_output = \"Upload a PDF to generate a test from its content.\"\n",
        "    status_message = \"Processing your requests...\"\n",
        "\n",
        "    # Concept Understanding\n",
        "    if concept.strip():\n",
        "        concept_output = get_concept_explanation(concept)\n",
        "    else:\n",
        "        concept_output = \"Enter a concept above to get an explanation.\"\n",
        "\n",
        "    # Language Learning\n",
        "    if language: # Radio button ensures a selection if user interacts\n",
        "        language_output = get_language_basics(language)\n",
        "    else:\n",
        "        language_output = \"Select a language above to learn its basics.\"\n",
        "\n",
        "    # PDF Test Generation\n",
        "    if pdf_file:\n",
        "        status_message = \"Extracting text from PDF and generating test...\"\n",
        "        pdf_text, pdf_error = extract_text_from_pdf(pdf_file)\n",
        "        if pdf_error:\n",
        "            test_pdf_output = pdf_error\n",
        "        elif pdf_text:\n",
        "            test_pdf_output = generate_test_from_content(pdf_text)\n",
        "        else:\n",
        "            test_pdf_output = \"Failed to extract text or generate test from PDF. Check file format.\"\n",
        "    else:\n",
        "        test_pdf_output = \"Upload a PDF file to generate a test from its content.\"\n",
        "\n",
        "    # Final status message\n",
        "    status_message = \"All learning requests processed.\"\n",
        "    return concept_output, language_output, test_pdf_output\n",
        "\n",
        "def process_quiz_request(quiz_topic: str) -> str:\n",
        "    \"\"\"\n",
        "    Generates a quiz for the given topic and formats it for display.\n",
        "    Returns: Formatted quiz string.\n",
        "    \"\"\"\n",
        "    if not quiz_topic.strip():\n",
        "        return \"Please enter a topic to generate a quiz.\"\n",
        "\n",
        "    quiz_data = generate_quiz_content(quiz_topic)\n",
        "\n",
        "    formatted_quiz_output = \"\"\n",
        "    if quiz_data:\n",
        "        formatted_quiz_output += f\"### Quiz on: {quiz_topic}\\n\\n\"\n",
        "        for i, q in enumerate(quiz_data):\n",
        "            formatted_quiz_output += f\"**Q{i+1}:** {q['question']}\\n\"\n",
        "            for option_key, option_value in q['options'].items():\n",
        "                formatted_quiz_output += f\"  **{option_key}.** {option_value}\\n\"\n",
        "            formatted_quiz_output += f\"  **Correct Answer:** {q['correct_answer']}\\n\\n\"\n",
        "    else:\n",
        "        formatted_quiz_output = \"Could not generate quiz for the given topic. The AI might not have sufficient knowledge or the request was too vague.\"\n",
        "\n",
        "    print(f\"Formatted Quiz Output for Gradio: {formatted_quiz_output}\")\n",
        "    return formatted_quiz_output\n",
        "\n",
        "# --- 8. Gradio User Interface Definition ---\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Soft(), title=\"EduTutor AI\") as interface:\n",
        "    gr.Markdown(\"# 👩‍🏫 EduTutor AI: Personalized Learning Platform\")\n",
        "    gr.Markdown(\"Welcome to EduTutor AI! Your personalized learning assistant. Login or Register to get started.\")\n",
        "\n",
        "    # State variable to hold the logged-in username\n",
        "    username_state = gr.State(\"\")\n",
        "\n",
        "    # Top-level Tabs for Login/Register\n",
        "    with gr.Tabs():\n",
        "        with gr.TabItem(\"Login\"):\n",
        "            with gr.Row():\n",
        "                login_user = gr.Textbox(label=\"Username\", placeholder=\"student1\", scale=1)\n",
        "                login_pwd = gr.Textbox(label=\"Password\", type=\"password\", placeholder=\"pass123\", scale=1)\n",
        "            login_button = gr.Button(\"Login\", variant=\"primary\", scale=0) # Scale=0 for auto-sizing\n",
        "            login_status = gr.Textbox(label=\"Login Status\", interactive=False, placeholder=\"Enter credentials and click Login.\")\n",
        "\n",
        "        with gr.TabItem(\"Register\"):\n",
        "            with gr.Row():\n",
        "                new_user = gr.Textbox(label=\"New Username\", placeholder=\"Enter desired username\", scale=1)\n",
        "                new_pwd = gr.Textbox(label=\"New Password\", type=\"password\", placeholder=\"Create a password\", scale=1)\n",
        "            register_button = gr.Button(\"Register\", variant=\"secondary\", scale=0)\n",
        "            registration_status = gr.Textbox(label=\"Registration Status\", interactive=False, placeholder=\"Click Register to create account.\")\n",
        "            register_button.click(fn=register_new_user, inputs=[new_user, new_pwd], outputs=registration_status)\n",
        "\n",
        "    # Main Application UI - Hidden until login\n",
        "    with gr.Column(visible=False, elem_id=\"app_ui_column\") as app_ui:\n",
        "        gr.Markdown(\"---\")\n",
        "        gr.Markdown(\"## Your Learning Hub\")\n",
        "        gr.Markdown(\"Use the tabs below to explore concepts, learn languages, generate tests from PDFs, or create quizzes.\")\n",
        "\n",
        "        # Tabs for different functionalities within the main app\n",
        "        with gr.Tabs():\n",
        "            with gr.TabItem(\"Concepts & Language\"):\n",
        "                gr.Markdown(\"### Explore Concepts and Learn Languages\")\n",
        "                with gr.Row():\n",
        "                    concept_input = gr.Textbox(\n",
        "                        label=\"Enter Concept to Explain (e.g., Photosynthesis, Machine Learning)\",\n",
        "                        placeholder=\"Generative AI\",\n",
        "                        lines=2, # More lines for concept input\n",
        "                        scale=2\n",
        "                    )\n",
        "                    language_radio = gr.Radio(\n",
        "                        choices=[\"English\", \"Hindi\", \"French\", \"Spanish\"], # Added more language options\n",
        "                        label=\"Choose Language for Basics\",\n",
        "                        value=\"English\", # Default selection\n",
        "                        scale=1\n",
        "                    )\n",
        "                pdf_upload = gr.File(\n",
        "                    label=\"Upload PDF for Test Generation (Optional)\",\n",
        "                    file_types=[\".pdf\"],\n",
        "                    file_count=\"single\" # Allow only one file\n",
        "                )\n",
        "\n",
        "                run_learning_btn = gr.Button(\"Get Explanations & Generate PDF Test\", variant=\"primary\")\n",
        "\n",
        "                gr.Markdown(\"---\")\n",
        "                gr.Markdown(\"### Outputs:\")\n",
        "                # Using Markdown components for outputs for better text rendering and copy button\n",
        "                concept_output_box = gr.Markdown(label=\"Concept Explanation\", show_copy_button=True)\n",
        "                language_output_box = gr.Markdown(label=\"Language Learning Basics\", show_copy_button=True)\n",
        "                pdf_test_output_box = gr.Markdown(label=\"Generated Test from PDF Content\", show_copy_button=True)\n",
        "\n",
        "                # Link the button click to the processing function\n",
        "                run_learning_btn.click(\n",
        "                    fn=process_learning_requests,\n",
        "                    inputs=[username_state, concept_input, language_radio, pdf_upload],\n",
        "                    outputs=[concept_output_box, language_output_box, pdf_test_output_box]\n",
        "                )\n",
        "\n",
        "            with gr.TabItem(\"Quiz Generator\"):\n",
        "                gr.Markdown(\"### Create a Quick Quiz on Any Topic\")\n",
        "                quiz_topic_input = gr.Textbox(\n",
        "                    label=\"Enter Topic for Quiz (e.g., World War II, Python Programming)\",\n",
        "                    placeholder=\"Artificial Intelligence\",\n",
        "                    lines=2\n",
        "                )\n",
        "                generate_quiz_btn = gr.Button(\"Generate Quiz\", variant=\"primary\")\n",
        "\n",
        "                gr.Markdown(\"---\")\n",
        "                gr.Markdown(\"### Generated Quiz:\")\n",
        "                # Changed to gr.Markdown for better formatting of the quiz content\n",
        "                # Added an initial placeholder text and set lines for visual space.\n",
        "                quiz_output_box = gr.Markdown(\n",
        "                    value=\"Your generated quiz will appear here. It may take a moment...\",\n",
        "                    label=\"Generated Quiz\",\n",
        "                    show_copy_button=True,\n",
        "                    # We don't use 'lines' with gr.Markdown directly, but the content will expand.\n",
        "                    # For a fixed box, you'd use gr.Textbox. If the content is long, Markdown works well.\n",
        "                )\n",
        "\n",
        "                # Link the quiz generation button\n",
        "                generate_quiz_btn.click(\n",
        "                    fn=process_quiz_request,\n",
        "                    inputs=[quiz_topic_input],\n",
        "                    outputs=[quiz_output_box]\n",
        "                )\n",
        "\n",
        "    # Link the login button to its handler\n",
        "    login_button.click(\n",
        "        fn=login_handler,\n",
        "        inputs=[login_user, login_pwd],\n",
        "        outputs=[app_ui, login_status, username_state]\n",
        "    )\n",
        "\n",
        "# --- 9. Launch the Gradio Interface ---\n",
        "# debug=True provides more console output for debugging.\n",
        "# share=True generates a public URL, useful for Colab.\n",
        "interface.launch(debug=True, share=True)"
      ]
    }
  ]
}